\section{Lec 8}
\subsection{Brief Recap}
We saw the WEP, that states $m_{i}= m_{g}$, and as consequence we get that is is impossible distinguish a gravitational field from motion, at least locally. \par
With the EEP we were able to derive the expression that quantify the gravitational redshift.
The SEP included gravity.\par

Focusing on EEP, we introduced \emph{Locally Inertial Frames, LIF} (equivalent to Freely Falling Frames).
Having accepted that gravity cannot be treated as a force, because it is impossible to disentangle acceleration due to gravity, we identified a preferred class of frames: LIFs.\par
In LIFs laws of physics are equal to the laws of SR and spacetime is\break Minkowskian.

We introduced Coordinates: with a generic set M, a chart, given a subset $U \subset M $, is a injective linear  map $\phi $, that \[
\phi : U \to \mathbb{R}^{n}
\]
An \emph{atlas }is an indexed $\{U_{\alpha}, \phi_{\alpha }\}$, in such a way that $U_{\alpha }$ cover \emph{M}.
A \emph{manifold} is a set M along with an atlas. A manifold can be $C^{\infty}$ if $\phi $ are differentiable an infinite amount of times, otherwise is $C^{p}$, differentiable p-times.
\subsubsection{Vectors again and again}
We resurrected $T_{P}$, \emph{P} generic \emph{M} point. $T_{P}$ is the vector space of all the vectors defined at that point.
\begin{quote}
$T_{P}$ is identified with the space of directional derivatives operators acting along the curves through \emph{P}
\end{quote}
Why this identification makes sense?\par
A generic curve through spacetime, that we call WL, is a parametric curve that is indicated by $x^{\mu }\left( \lambda  \right)$: for a specific value of $\lambda $ I have the $x^{\mu }$ point.
\[
x^{\mu }\left( \overline{\lambda } \right) = P
\]
How do I define the directional derivatives?
Be \[
\frac{d}{d\lambda }
\]
that acts on functions, \emph{f},
\[
f : M \to \mathbb{R}
\]
then $\forall f$:
\[
\frac{d}{d\lambda } = \frac{dx^{\mu }}{d\lambda }\partial_{\mu }
\]
We see that it is like a basis.\par
\textbf{Basis vectors } for $T_{P}\to \partial_{\mu }$. (we previously called them $\hat{e}_{\left( \mu  \right)}$). \par
In conclusion a generic vector is 
\[
V = V^{\mu }\partial_{\mu }
\]
where $V^{\mu }$ are the components, and $\partial_{\mu }$ are the basis elements.\par

It's very easy to show how vectors transform because we know how derivatives transform:
\begin{equation}
\frac{\partial}{\partial  x^{\mu'}} = \frac{\partial  x^{\mu }}{\partial  x^{\mu '}} \frac{\partial}{\partial  x^{\mu }}
\end{equation}
or in a tensor-like notation:
\begin{equation}
\partial_{\mu '} = \frac{\partial  x^{\mu }}{\partial x^{\mu '}} \partial_{\mu }
\end{equation}
If \emph{V} tensor is invariant, by definition, it's components transform anyway like
\[
V^{\mu '} = \frac{\partial x^{\mu '}}{\partial x^{\mu }}V^{\mu }
\]

\paragraph{Example} LTs
\[
x^{\alpha '} = \Lambda^{\alpha '}_{\alpha }x^{\alpha }
\]
I consider a specific change of coordinates: LTs, so
\[
\frac{\partial x^{\mu '}}{\partial x^{\mu }} = \frac{\partial}{\partial x^{\mu }} \left( \Lambda^{\mu '}_{\alpha }x^{\alpha } \right) = \Lambda^{\mu '}_{\alpha } \frac{\partial x^{\alpha }}{\partial x^{\mu }} = \Lambda^{\mu '}_{\alpha } \delta^{\alpha }_{\mu } = \Lambda^{\mu '}_{\mu }
\]
we get under more general transformations vectors components transform like this, and more, we recovered the LT transformation.

\subsection{Dual Vectors}
Be the \emph{cotangent space} $T_{P}^{*}$. If $\omega \in T_{P}^{*}$, $\omega$ is a linear map that  $\omega : T_{P}\to \mathbb{R}$.
We want to define formally $T_{P}^{*}$ (like we did for $T_{P}$).
We know that the tangent space $T_{P}$ holds directional derivatives, while cotangent space $T_{P}^{*}$ holds gradients. \par
For a generic $f: M\to \mathbb{R}$:
\begin{gather*}
\frac{d}{d\lambda } \in T_{P} \\
d \in T_{P}^{*} \\
\text{ and so } \\
df \left( \frac{d}{d\lambda } \right) \equiv \frac{df}{d\lambda }\\
\downarrow \quad\; \downarrow \qquad \;\downarrow \\
\in T_{P}^{*}, \in T_{P}, \in \mathbb{R}
\end{gather*}
\textbf{Basis} for T\textsubscript{P}\textsuperscript{*}: $dx^{\mu }$.\par
\[
dx^{\mu } \left( \frac{\partial}{\partial x^{\nu }} \right) = \frac{\partial x^{\mu }}{\partial x^{\nu }} = \delta^{\mu }_{\nu }
\]
that is the same as the old $\hat{O}^{\left( \mu  \right)}\left( \hat{e}_{\nu } \right)=\delta^{\mu }_{\nu }$.

A dual vector is \[
\omega = \omega_{\mu }dx^{\mu }
\]
the basis component transform like
\[
dx^{\mu '} = \frac{\partial x^{\mu '}}{\partial x^{\mu }} dx^{\mu }
\]
and the vector components
\[
\omega_{\mu '} = \frac{\partial x^{\mu }}{\partial x^{\mu '}}\omega_{\mu }
\]

\subsection{Tensors (k,l)}
\[
T : T_{P}^{*}\times \ldots \times T_{P}^{*} \times T_{P}\times \ldots \times T_{P}\to \mathbb{R}
\]
Tensors can be expanded into components:
\[
T = T^{\mu_{1}\ldots \mu_{k}}_{\nu_{1}\ldots \nu_{l}} \left( \partial_{\mu_{1}} \otimes \ldots \otimes \partial_{\mu_{k}} \otimes dx^{\nu_{1}} \otimes \ldots \otimes dx^{\nu_{l}} \right)
\]
So the components of a generic tensor transform like
\[
T^{\mu_{1}' \ldots \mu_{k}'}_{\nu_{1}' \ldots \nu_{l}'} = \left( \frac{\partial x^{\mu_{1}'}}{\partial x^{\mu_{1}}} \ldots \frac{\partial x^{\nu_{1}}}{\partial x^{\nu_{1}'}}\ldots  \right) T^{\mu_{1}\ldots \mu_{k}}_{\nu_{1}\ldots \nu_{l}}
\]

Now let's see a unusual tensor, it's a (2,1) tensor, how does transform?
\[
T^{\alpha' \beta'}_{\gamma'} = \frac{\partial x^{\alpha '}}{\partial x^{\alpha }} \frac{\partial x^{\beta '}}{\partial x^{\beta }} \frac{\partial x^{\gamma }}{\partial x^{\gamma '}} T^{\alpha \beta }_{\gamma }	 
\]
\paragraph{Example/exercise} (from 2.4 of Carroll)
Be a tensor $S_{ij}$, with $i,j =1,2$, so it's a (0,2) tensor.
We know that
\begin{itemize}
	\item S\textsubscript{11} = 1
	\item S\textsubscript{12}=S\textsubscript{21} = 0
	\item S\textsubscript{22} = x\textsuperscript{2}
\end{itemize}
We get new coordinates:
\begin{gather*}
x' = \frac{2x}{y} \\
y' = \frac{y}{2}
\end{gather*}
What are the expressions for $S_{i'j'}$?\par
One could think to compute each entry doing
\[
S_{i'j'}= \frac{\partial x^{i}}{\partial x^{i'}} \frac{\partial x^{j}}{\partial x^{j'}} S_{ij}
\]
So, like the (1,1) one looks like
\[
S_{1'1'} = \frac{\partial x^{i}}{\partial x^{1'}} \frac{\partial x^{j}}{\partial x^{1'}} S_{ij}
\]
It is good exercise to do this. (see sec \ref{ex:changebasis})
But it seems that there is a much faster way than this.\par
We can write the tensor $S$ as
\[
S = S_{\mu \nu }\left( dx^{\mu } \otimes dx^{\nu } \right)
\]
and for our case 
\[
S = S_{ij}\left( dx^{i} \otimes dx^{j} \right)
\]
The action of this tensor could be written as 
\begin{equation}\label{eq:1}
S \left( dx^{i},dx^{j} \right) = S_{11}dx^{2} + S_{12}dxdy + S_{21}dydx + S_{22}dy^{2} = dx^{2} +x^{2}dy^{2}		
\end{equation}
the two middle terms are not grouped because tensor product does not commute.\par

Now we can take the inverse coordinate transformation and write it down.
\begin{equation}
\begin{cases}
x = x'y' \\
 y = 2y'\\
\end{cases} \to 
\begin{cases}
dx = x'dy' + y'dx' \\
dy = 2dy' \\
\end{cases}
\end{equation}
and then we substitute inside eq. [\ref{eq:1}], getting
\begin{gather*}
	\left( x'dy' + y'dx' \right)^{2} + 4dy'^{2} = \\
	x'^{2}dy'^{2} + y'^{2}dx'^{2} + x'y'\left( dx'dy'+dy'dx' \right) + 4dy'^{2} 
\end{gather*}
so we get:
\begin{equation}
\begin{cases}
S_{ii} = y'^{2} \\
S_{ij} = S_{ji} = x'y' \\
S_{jj} = x'^{2} + 4\left( x'y' \right)^{2}
\end{cases}
\to 
\begin{pmatrix}
y'^{2} & x'y' \\
x'y' & x'^{2}+4\left( x'y' \right)^{2}
\end{pmatrix} = S_{i'j'} 
\end{equation}

\subsection{Special Tensors}
Special tensor that we will see are
\begin{itemize}
	\item Derivative
	\item Metric tensor
	\item Levi-Civita Symbol
\end{itemize}

\subsubsection{Partial derivative}
We will show that the partial derivative of a tensor is not a tensor anymore.\par

Derivative of a scalar is a (0,1) tensor.
\[
\partial_{\mu }\phi \to \partial_{\mu '}\phi = \frac{\partial x^{\mu }}{\partial x^{\mu '}} \partial_{\mu }\phi 
\]
$\phi $ does not change under transformation, but the derivative does.

Derivative of a tensor $\neq$ tensor:\par
\textbf{example} : 
\[
A_{\mu \nu } = \partial_{\mu }V_{\nu }
\]
But why? \par
Let's transform it:
\begin{gather*}
A_{\mu '\nu '} = \partial_{\mu '}V_{\nu '} = \frac{\partial x^{\mu }}{\partial x^{\mu '}} \frac{\partial }{\partial x^{\mu }} \left( \frac{\partial x^{\nu }}{\partial x^{\nu '}}V_{\nu }  \right) = \\
\text{now if we apply the partial derivative we obtain}\\
= \frac{\partial x^{\mu }}{\partial x^{\mu '}} \frac{\partial x^{\nu }}{\partial x^{\nu '}} \partial_{\mu } V_{\nu } + \left( \frac{\partial x^{\mu }}{\partial x^{\mu '}}  \right)\left( \frac{\partial^{2}x^{\nu }}{\partial x^{\nu '}\partial x^{\mu }}  \right)V_{\nu }
\end{gather*}
What happened? We see there is a piece that we don't like. This second piece is 0 for LTs, because they are linear so second derivatives are null. This because in Euclidean space the derivative is independent on the coordinates, and on Minkowski space too, since it's flat. \par
The tensor itself is independent of the coordinate system, but the operation of taking a partial derivative is highly dependent on what coordinate system you're using.\par
We give importance to this anyway because GR is not a theory for just LTs.
We will develop a covariant derivative that applied to a tensor will give back a tensor.

\subsubsection{Metric tensor}
The roles of the metric tensor are many:
\begin{itemize}
	\item allows the computation of path length and proper time
	\item replaces the Newtonian gravitational field $\phi $
	\item provides a notion of locally inertial frames
	\item replaces the Euclidean 3D dot product of Newtonian mechanics.
\end{itemize}

We know the Minkowski's one:
\begin{equation}
\eta_{\mu \nu } = \text{diag }\left( -1,1,1,1 \right) = \begin{pmatrix}
-1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1
\end{pmatrix} 
\end{equation}
\bigskip
In general $g_{\mu \nu }$ will be the metric tensor.\par
We assume the determinant of $g_{\mu \nu }: \text{det}\left( g_{\mu \nu } \right) \equiv g \neq 0 \to $ the metric tensor is \emph{invertible}.
\[
g_{\mu \nu }g^{\nu \alpha } = \delta^{\alpha }_{\mu } \text{ ; } g^{\mu \nu }g_{\nu \alpha } = \delta^{\mu }_{\alpha }
\]
A constant metric tensor implies no curvature. But the opposite is not true.\par
A metric tensor that depends explicitly on the coordinates must describe a non-flat space? \textbf{FALSE} e.g. the polar coordinates: writing $\eta_{\mu \nu }$ in them
\begin{equation}
\eta_{\mu \nu }^{\left(polar\right)} = \begin{pmatrix}
-1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0 & r^{2} & 0 \\
0 & 0 & 0 & r^{2} \text{sin}^{2}\theta ,
\end{pmatrix} 
\end{equation}.
Given a generic metric $g_{\mu \nu }$ and a given event P, it is always possible to find new coordinates:
\[
g_{\hat{\mu }\hat{\nu }} = \frac{\partial x^{\mu }}{\partial x^{\hat{\mu }}} \frac{\partial x^{\nu }}{\partial x^{\hat{\nu }}} g_{\mu \nu }
\]
And
\[
g_{\hat{\mu }\hat{\nu }}\left( P \right) = \eta_{\hat{\mu }\hat{\nu }} \text{ ; } \partial_{\hat{\sigma }}g_{\hat{\mu }\hat{\nu }}\left( P \right)=0
\]
This recalls the definition of LIFs.


\subsection{Applying tensor transformation formula}\label{ex:changebasis}

This is the suggested-to-try alternative way to do the exercise about tensor change of basis. I did it, and since I'm not that good with tensors I thought it is not trivial so will report here.\par
\[
S_{i\prime j\prime } = \frac{\partial x^{i}}{\partial x^{i\prime }} \frac{\partial x^{j}}{\partial x^{j\prime }} S_{ij}
\]
Partial derivatives are a jacobian. So one need to express \emph{x,y} in terms of $x^{\prime },y^{\prime }$, and then derive them to fill the jacobian
\begin{equation}
\frac{\partial x^{i}}{\partial x^{i\prime }}  = \begin{pmatrix}
\partial x /\partial x^{\prime } & \partial x / \partial y^{\prime } \\
\partial y / \partial x^{\prime } & \partial y / \partial y^{\prime }
\end{pmatrix} 
\end{equation}
Express $S_{ij}$ in terms of $x^{\prime }, y^{\prime }$:
\[
S_{ij} = \begin{pmatrix}
1 & 0 \\
0 & \left( x^{\prime }y^{\prime } \right)^{2}
\end{pmatrix} 
\]
And then compute each entry
\[
S_{1^{\prime }1^{\prime }} = \frac{\partial x^{i}}{\partial x^{1\prime }} \frac{\partial x^{j}}{\partial x^{1\prime }} S_{ij} 
\]
et cetera. 


